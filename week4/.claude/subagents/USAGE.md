# SubAgents Usage Guide

## Overview
SubAgents are specialized AI assistants that work together to implement features using Test-Driven Development (TDD). Each agent has a specific role and expertise.

## Available Agents

### ğŸ§ª TestAgent
- **Role**: Testing specialist
- **Config**: `.claude/subagents/test-agent.md`
- **Expertise**: Writing comprehensive tests, TDD methodology
- **Responsibilities**: Write failing tests first, verify implementations

### âš™ï¸ CodeAgent
- **Role**: Implementation specialist
- **Config**: `.claude/subagents/code-agent.md`
- **Expertise**: FastAPI, SQLAlchemy, clean code
- **Responsibilities**: Implement features to pass tests, format code

## How It Works

### TDD Workflow with SubAgents:

```
User Request
    â†“
TestAgent (Red Phase)
    â†’ Writes failing tests
    â†’ Documents test scenarios
    â†’ Hands off to CodeAgent
    â†“
CodeAgent (Green Phase)
    â†’ Reviews tests
    â†’ Implements features
    â†’ Formats code
    â†’ Hands back to TestAgent
    â†“
TestAgent (Verification)
    â†’ Runs tests
    â†’ Reports results
    â†’ Suggests fixes (if needed)
    â†“
Done! âœ…
```

## Usage Examples

### Example 1: Add UPDATE endpoint for notes

#### Step 1: Invoke TestAgent
```
You: "TestAgent, please write tests for PUT /notes/{id} endpoint that updates a note's title and content."

TestAgent:
ğŸ§ª TestAgent here!

I'll write tests for: PUT /notes/{id} - Update note endpoint

Test scenarios:
1. Successfully update note with valid data
2. Update note with partial data (only title or only content)
3. Return 404 when note doesn't exist
4. Return 422 when data is invalid

Working on it...

[Creates backend/tests/test_notes.py with tests]

âœ… Tests written!
ğŸ“ File: backend/tests/test_notes.py
ğŸ“Š Test cases: 4
  - Success: 2
  - Error (404): 1
  - Error (422): 1

ğŸ”´ Current status: FAILING (as expected in TDD)

ğŸ¤ Handing off to CodeAgent for implementation!
```

#### Step 2: Invoke CodeAgent
```
You: "CodeAgent, please implement the update endpoint to pass TestAgent's tests."

CodeAgent:
âš™ï¸ CodeAgent here!

Received tests from TestAgent:
- File: backend/tests/test_notes.py
- Tests: 4 test cases

Implementation plan:
1. Add NoteUpdate schema to schemas.py
2. Add PUT /notes/{id} endpoint to routers/notes.py
3. Handle validation and 404 errors
4. Format code

Starting implementation...

[Implements the feature]

âœ… Implementation complete!

ğŸ“ Files modified:
  â€¢ backend/app/schemas.py - Added NoteUpdate schema
  â€¢ backend/app/routers/notes.py - Added update_note endpoint

ğŸ¯ Features implemented:
  â€¢ PUT /notes/{id} endpoint
  â€¢ Partial update support
  â€¢ Error handling (404, 422)

ğŸ”§ Code formatted with black/ruff

ğŸ¤ Handing back to TestAgent for verification!
```

#### Step 3: TestAgent Verification
```
You: "TestAgent, please verify the implementation."

TestAgent:
ğŸ§ª Test Verification Results:

Running: pytest backend/tests/test_notes.py::test_update_note* -v

âœ… All tests passed! (4/4)

Test results:
  âœ… test_update_note_success
  âœ… test_update_note_partial
  âœ… test_update_note_not_found
  âœ… test_update_note_invalid_data

ğŸ‰ Implementation verified! Feature is complete.
```

### Example 2: Add DELETE endpoint

#### Single command approach:
```
You: "I need a DELETE /notes/{id} endpoint. TestAgent, write tests. CodeAgent, implement it. TestAgent, verify."

[Both agents work in sequence]

TestAgent: âœ… Tests written (3 test cases)
CodeAgent: âœ… Implementation complete
TestAgent: âœ… All tests passed! (3/3)
```

### Example 3: Fix failing tests

```
You: "TestAgent, some tests are failing. Please investigate."

TestAgent:
ğŸ§ª Running tests...

âŒ Tests failed: (2/8)

Failed tests:
- test_search_notes_empty_query: Expected 200, got 500
- test_search_notes_special_chars: SQL error with '%' character

Root cause: search endpoint doesn't handle None or special characters

Suggested fixes:
1. Add null check for query parameter
2. Escape special SQL characters

You: "CodeAgent, please fix these issues."

CodeAgent:
âš™ï¸ Fixing issues...
[Makes fixes]
âœ… Complete!

You: "TestAgent, verify the fixes."

TestAgent:
âœ… All tests passed! (8/8)
```

## Best Practices

### 1. Always start with TestAgent
```
âŒ Bad: "CodeAgent, add a search feature"
âœ… Good: "TestAgent, write tests for search feature"
```

### 2. Let agents hand off to each other
```
TestAgent completes â†’ Hands to CodeAgent
CodeAgent completes â†’ Hands to TestAgent
```

### 3. Be specific in requirements
```
âŒ Vague: "Add update functionality"
âœ… Specific: "Add PUT /notes/{id} that updates title and content, returns 404 if not found"
```

### 4. Verify after implementation
```
Always: TestAgent â†’ CodeAgent â†’ TestAgent (verify)
```

### 5. Use agents for their expertise
```
TestAgent:
  - Write tests
  - Verify implementations
  - Suggest test scenarios

CodeAgent:
  - Implement features
  - Fix bugs
  - Refactor code
```

## Advanced Usage

### Parallel work (independent features):
```
Session 1 (TestAgent): Write tests for tags feature
Session 2 (CodeAgent): Implement users feature (already has tests)
Session 3 (TestAgent): Verify users feature
```

### Iterative refinement:
```
TestAgent: Write basic tests
CodeAgent: Implement
TestAgent: "Tests pass but we need edge cases"
TestAgent: Add more tests (now failing)
CodeAgent: Fix implementation
TestAgent: âœ… All pass
```

### Code review workflow:
```
CodeAgent: Implement feature
TestAgent: Review + write tests
User: "Add this edge case"
TestAgent: Add test for edge case
CodeAgent: Fix implementation
TestAgent: âœ… Verified
```

## Troubleshooting

### Tests won't pass:
1. TestAgent: Review test requirements
2. CodeAgent: Check implementation
3. User: Verify requirements are correct

### Agents confused:
1. Start fresh conversation
2. Be more specific in request
3. Reference existing files explicitly

### Merge conflicts:
1. CodeAgent: Review both implementations
2. Choose best approach
3. TestAgent: Verify merged code

## Integration with Other Tools

### With slash commands:
```
/add-crud Tag "name:str, color:str"  # Generate basic CRUD
TestAgent: Add edge case tests       # Enhance tests
CodeAgent: Handle edge cases          # Improve implementation
```

### With CLAUDE.md:
- Agents automatically follow project conventions
- No need to repeat style rules
- Consistent code across agents

## Success Checklist

Before considering a feature complete:
- âœ… TestAgent wrote comprehensive tests
- âœ… CodeAgent implemented feature
- âœ… TestAgent verified all tests pass
- âœ… Code is formatted (black/ruff)
- âœ… Error handling included
- âœ… Follows project conventions

## Quick Reference

### Invoke TestAgent:
```
"TestAgent, write tests for <feature>"
"TestAgent, verify the implementation"
"TestAgent, add edge case tests for <scenario>"
```

### Invoke CodeAgent:
```
"CodeAgent, implement <feature> to pass tests"
"CodeAgent, fix the failing tests"
"CodeAgent, refactor <module>"
```

### Full workflow:
```
"TestAgent, write tests for <feature>. CodeAgent, implement it. TestAgent, verify."
```